{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pprint\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_set = open(\"ml-1m/ratings.dat\").readlines()\n",
    "train_set = np.random.permutation(train_set)[:100]\n",
    "train_threshold = int(0.75 * len(train_set))\n",
    "# train_indices = []\n",
    "# test_indices = []\n",
    "train_user_indices = []\n",
    "train_item_indices = []\n",
    "test_user_indices = []\n",
    "test_item_indices = []\n",
    "train_ratings = []\n",
    "test_ratings = []\n",
    "\n",
    "data = defaultdict(dict)\n",
    "user2id = {}\n",
    "item2id = {}\n",
    "index_user = 0\n",
    "index_item = 0\n",
    "\n",
    "for i, line in enumerate(train_set):\n",
    "    user = line.split(\"::\")[0]\n",
    "    item = line.split(\"::\")[1]\n",
    "    rating = line.split(\"::\")[2]\n",
    "    \n",
    "    try:\n",
    "        user_id = user2id[user]\n",
    "    except KeyError:\n",
    "        user_id = index_user\n",
    "        user2id[user] = index_user\n",
    "        index_user += 1\n",
    "    try:\n",
    "        item_id = item2id[item]\n",
    "    except KeyError:\n",
    "        item_id = index_item\n",
    "        item2id[item] = index_item\n",
    "        index_item += 1\n",
    "        \n",
    "    if i < train_threshold:\n",
    "    #    train_indices.append((user_id, item_id))\n",
    "        train_user_indices.append(user_id)\n",
    "        train_item_indices.append(item_id)\n",
    "        train_ratings.append(int(rating))\n",
    "        data[user_id].update(dict(zip([item_id], [int(rating)])))\n",
    "    else:\n",
    "    #    test_indices.append((user_id, item_id))\n",
    "        test_user_indices.append(user_id)\n",
    "        test_item_indices.append(item_id)\n",
    "        test_ratings.append(int(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ratings), len(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ratings(dataset):\n",
    "    for user, r in data.items():\n",
    "        for item, rating in r.items():\n",
    "            yield user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(user2id)\n",
    "n_items = len(item2id)\n",
    "n_factors = 100\n",
    "user_list = np.array(list(data.keys()), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, names=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
    "aa = aa.filter(regex=\"user|item|rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1  1193       5\n",
       "1     1   661       3\n",
       "2     1   914       3\n",
       "3     1  3408       4\n",
       "4     1  2355       5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': {0: 1193,\n",
       "  1: 661,\n",
       "  2: 914,\n",
       "  3: 3408,\n",
       "  4: 2355,\n",
       "  5: 1197,\n",
       "  6: 1287,\n",
       "  7: 2804,\n",
       "  8: 594,\n",
       "  9: 919,\n",
       "  10: 595,\n",
       "  11: 938,\n",
       "  12: 2398,\n",
       "  13: 2918,\n",
       "  14: 1035,\n",
       "  15: 2791,\n",
       "  16: 2687,\n",
       "  17: 2018,\n",
       "  18: 3105,\n",
       "  19: 2797,\n",
       "  20: 2321,\n",
       "  21: 720,\n",
       "  22: 1270,\n",
       "  23: 527,\n",
       "  24: 2340,\n",
       "  25: 48,\n",
       "  26: 1097,\n",
       "  27: 1721,\n",
       "  28: 1545,\n",
       "  29: 745,\n",
       "  30: 2294,\n",
       "  31: 3186,\n",
       "  32: 1566,\n",
       "  33: 588,\n",
       "  34: 1907,\n",
       "  35: 783,\n",
       "  36: 1836,\n",
       "  37: 1022,\n",
       "  38: 2762,\n",
       "  39: 150,\n",
       "  40: 1,\n",
       "  41: 1961,\n",
       "  42: 1962,\n",
       "  43: 2692,\n",
       "  44: 260,\n",
       "  45: 1028,\n",
       "  46: 1029,\n",
       "  47: 1207,\n",
       "  48: 2028,\n",
       "  49: 531,\n",
       "  50: 3114,\n",
       "  51: 608,\n",
       "  52: 1246},\n",
       " 'rating': {0: 5,\n",
       "  1: 3,\n",
       "  2: 3,\n",
       "  3: 4,\n",
       "  4: 5,\n",
       "  5: 3,\n",
       "  6: 5,\n",
       "  7: 5,\n",
       "  8: 4,\n",
       "  9: 4,\n",
       "  10: 5,\n",
       "  11: 4,\n",
       "  12: 4,\n",
       "  13: 4,\n",
       "  14: 5,\n",
       "  15: 4,\n",
       "  16: 3,\n",
       "  17: 4,\n",
       "  18: 5,\n",
       "  19: 4,\n",
       "  20: 3,\n",
       "  21: 3,\n",
       "  22: 5,\n",
       "  23: 5,\n",
       "  24: 3,\n",
       "  25: 5,\n",
       "  26: 4,\n",
       "  27: 4,\n",
       "  28: 4,\n",
       "  29: 3,\n",
       "  30: 4,\n",
       "  31: 4,\n",
       "  32: 4,\n",
       "  33: 4,\n",
       "  34: 4,\n",
       "  35: 4,\n",
       "  36: 5,\n",
       "  37: 5,\n",
       "  38: 4,\n",
       "  39: 5,\n",
       "  40: 5,\n",
       "  41: 5,\n",
       "  42: 4,\n",
       "  43: 4,\n",
       "  44: 4,\n",
       "  45: 5,\n",
       "  46: 5,\n",
       "  47: 4,\n",
       "  48: 5,\n",
       "  49: 4,\n",
       "  50: 4,\n",
       "  51: 4,\n",
       "  52: 4},\n",
       " 'user': {0: 1,\n",
       "  1: 1,\n",
       "  2: 1,\n",
       "  3: 1,\n",
       "  4: 1,\n",
       "  5: 1,\n",
       "  6: 1,\n",
       "  7: 1,\n",
       "  8: 1,\n",
       "  9: 1,\n",
       "  10: 1,\n",
       "  11: 1,\n",
       "  12: 1,\n",
       "  13: 1,\n",
       "  14: 1,\n",
       "  15: 1,\n",
       "  16: 1,\n",
       "  17: 1,\n",
       "  18: 1,\n",
       "  19: 1,\n",
       "  20: 1,\n",
       "  21: 1,\n",
       "  22: 1,\n",
       "  23: 1,\n",
       "  24: 1,\n",
       "  25: 1,\n",
       "  26: 1,\n",
       "  27: 1,\n",
       "  28: 1,\n",
       "  29: 1,\n",
       "  30: 1,\n",
       "  31: 1,\n",
       "  32: 1,\n",
       "  33: 1,\n",
       "  34: 1,\n",
       "  35: 1,\n",
       "  36: 1,\n",
       "  37: 1,\n",
       "  38: 1,\n",
       "  39: 1,\n",
       "  40: 1,\n",
       "  41: 1,\n",
       "  42: 1,\n",
       "  43: 1,\n",
       "  44: 1,\n",
       "  45: 1,\n",
       "  46: 1,\n",
       "  47: 1,\n",
       "  48: 1,\n",
       "  49: 1,\n",
       "  50: 1,\n",
       "  51: 1,\n",
       "  52: 1}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[aa.user == 1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([1]), dict_values([5]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].keys(), data[1].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1193, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.iloc[0].to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ratings2(dataset):\n",
    "    for user, item, rating in zip(dataset.user, dataset.item, dataset.rating):\n",
    "        yield user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.arange(16).reshape(4,4)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 8, 10]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take_along_axis(aa[[0,2]], np.array([[0,2]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 8, 10]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(aa[[0,2]], [0,2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 8, 10]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[[0,2]][:, [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10, 11])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[[0,2,2], [1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 2],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(aa, list(zip(index1, index2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]), array([2]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(aa == 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNDO :  common calculate   raw_id2inner_id  pearson_similarity  predict_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common(x1,x2):\n",
    "    # find common ratings\n",
    "    common = (x1 != 0) & (x2 != 0)\n",
    "    new_x1 = x1[common]\n",
    "    new_x2 = x2[common]\n",
    "    return new_x1, new_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3]), array([1, 4]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,0])\n",
    "x1 = np.array([1,0, 4, 6])\n",
    "c = (x != 0) & (x1 != 0)\n",
    "x[c], x1[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common(x1, x2):\n",
    "    common = (x1 != 0) & (x2 != 0)\n",
    "    new_x1 = x1[common]\n",
    "    new_x2 = x2[common]\n",
    "    return new_x1, new_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 5, 5]), array([2, 3, 5]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([4,0,5,5])\n",
    "x2 = np.array([2,1,3,5])\n",
    "common(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2), (5, 3), (5, 5)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(common(x1, x2)[0], common(x1, x2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7559289460184546"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator = 0\n",
    "denominator1 = 0\n",
    "denominator2 = 0\n",
    "mean1 = np.mean(common(x1, x2)[0])\n",
    "mean2 = np.mean(common(x1, x2)[1])\n",
    "for i, j in zip(common(x1, x2)[0], common(x1, x2)[1]):\n",
    "    numerator += (i - mean1) * (j - mean2)\n",
    "    denominator1 += (i - mean1) ** 2\n",
    "    denominator2 += (j - mean2) ** 2\n",
    "\n",
    "numerator / (np.sqrt(denominator1) * np.sqrt(denominator2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = defaultdict(dict)\n",
    "for key in range(200):\n",
    "#    key = str(key)\n",
    "    example[key] = data[key]\n",
    "# data = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ True,  True,  True, False,  True],\n",
       "        [ True, False,  True, False,  True]]), array([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 4],\n",
       "        [1, 0],\n",
       "        [1, 2],\n",
       "        [1, 4]]), array([1., 2., 3., 2., 1., 3., 3.], dtype=float32), array([1., 2., 3., 2., 1., 3., 3.], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(np.array([[1,2,3,0,2], [1,0,3,0,3]]), dtype=tf.float32)\n",
    "zero = tf.constant(0, dtype=tf.float32)  ## -1\n",
    "mask = tf.not_equal(a, zero)\n",
    "# indices = tf.reshape(tf.where(mask), shape=[-1])\n",
    "indices = tf.where(mask)\n",
    "c = tf.gather_nd(a, indices)\n",
    "d = tf.boolean_mask(a, mask)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run([mask, indices, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  7,  8, 10,  9, 14, 17, 17, 17, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(a):\n",
    "    return a[0] + a[1] + a[2]\n",
    "\n",
    "aa = np.array(train_user_indices)[:10]\n",
    "bb = np.array(train_item_indices)[:10]\n",
    "cc = np.array(train_ratings)[:10]\n",
    "nu = tf.map_fn(func, [aa, bb, cc], dtype=tf.int64)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3], dtype=int32), 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([[1,2,3,0,0], [4,5,6,7,8]], dtype=np.int32)\n",
    "oo = tf.nn.embedding_lookup(aa, 0)\n",
    "zero = tf.constant(0, dtype=tf.int32)\n",
    "mask = tf.not_equal(oo, zero)\n",
    "u_items_mask = tf.boolean_mask(oo, mask)\n",
    "# ii = tf.gather(oo, u_items_mask)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run([u_items_mask, tf.size(u_items_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0599637 ,  0.10894931,  0.02212552, ...,  0.06748607,\n",
       "         -0.17401433, -0.09068567],\n",
       "        [ 0.01508748,  0.01031978,  0.00728436, ...,  0.02157799,\n",
       "         -0.03474513, -0.06860533],\n",
       "        [ 0.0499043 ,  0.04905506, -0.09098595, ...,  0.2249795 ,\n",
       "          0.03475139, -0.01830734],\n",
       "        ...,\n",
       "        [-0.02819956, -0.00509941,  0.00060968, ..., -0.02477363,\n",
       "         -0.00529699,  0.01257202],\n",
       "        [-0.01476342, -0.00543445, -0.00674025, ..., -0.0633116 ,\n",
       "         -0.00543289,  0.00431837],\n",
       "        [-0.0382369 ,  0.04862677, -0.00541936, ...,  0.00024505,\n",
       "          0.03966409,  0.00907592]], dtype=float32),\n",
       " array([6040,  100], dtype=int32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.zeros((n_users, n_items), dtype=np.int32)\n",
    "for u in data:\n",
    "    u_items = list(data[u].keys())\n",
    "    train_data[u] = np.array(u_items + [0] * (n_items - len(u_items)))\n",
    "\n",
    "pseudo_data = tf.placeholder(tf.int32, shape=[n_users, n_items])\n",
    "yj = tf.Variable(tf.random_normal([n_items, n_factors], 0.0, 0.01))\n",
    "\n",
    "def nu_func(user):\n",
    "    u_items = tf.nn.embedding_lookup(pseudo_data, user)\n",
    "    zero = tf.constant(0, dtype=tf.int32)\n",
    "    mask = tf.not_equal(u_items, zero)\n",
    "    u_items_mask = tf.boolean_mask(u_items, mask)\n",
    "    return tf.reduce_sum(tf.gather(yj, u_items_mask), axis=0)\n",
    "\n",
    "user_list = np.array(list(data.keys()), dtype=np.int32)\n",
    "nu = tf.map_fn(nu_func, user_list, dtype=tf.float32)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run([nu, tf.shape(nu)], feed_dict={pseudo_data: train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 22, 27],\n",
       "       [22, 29, 36],\n",
       "       [27, 36, 45]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([1,2,3]).reshape(1,-1)\n",
    "bb = np.array([4,5,6]).reshape(1, -1)\n",
    "aa.T.dot(aa) + bb.T.dot(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 22, 27],\n",
       "       [22, 29, 36],\n",
       "       [27, 36, 45]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = np.array([[1,2,3],[4,5,6]])\n",
    "cc.T.dot(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1],\n",
       "        [4, 4, 4, 4],\n",
       "        [9, 9, 9, 9]]), array([14, 14, 14, 14]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([1,2,3])\n",
    "aa = np.expand_dims(aa, axis=1)\n",
    "bb = np.array([[1,1,1,1], [2,2,2,2], [3,3,3,3]])\n",
    "aa * bb, np.sum(np.multiply(aa, bb), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Meets the Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, names=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
    "aa = aa.filter(regex=\"user|item|rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1193, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.iloc[0].to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ratings2(dataset):\n",
    "    for user, item, rating in zip(dataset.user, dataset.item, dataset.rating):\n",
    "        yield user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.zeros((n_users, n_items), dtype=np.int32)\n",
    "for u in data:\n",
    "    u_items = list(data[u].keys())\n",
    "    train_data[u] = np.array(u_items + [-1] * (n_items - len(u_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1371, 1992,  202,  139,  269,   15, 1176,  533, 2200, 1124,\n",
       "        282,  591,  989,  224,  737, 1763,  804,  549, 1063, 3049, 1519,\n",
       "       1457, 2696, 2345, 1019], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.placeholder(tf.int32, shape=[None, len(item2id)])\n",
    "oo = tf.nn.embedding_lookup(aa, 1)\n",
    "zero = tf.constant(-1, dtype=tf.int32)\n",
    "mask = tf.not_equal(oo, zero)\n",
    "u_items_mask = tf.boolean_mask(oo, mask)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(u_items_mask, feed_dict={aa: train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 18], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.constant([[1,2,3], [4,5,6]])\n",
    "bb = tf.gather(tf.gather(aa, 0), [1,1])\n",
    "test_user = tf.placeholder(tf.int32, shape=[None])\n",
    "test_item = tf.placeholder(tf.int32, shape=[None])\n",
    "# elems = (np.array([1,2,3]), np.array([4,5,6]))\n",
    "def func(x):\n",
    "    q = x[0]\n",
    "    r = x[1]\n",
    "    return q * r\n",
    "\n",
    "cc = tf.map_fn(func, (test_user, test_item), dtype=tf.int32)\n",
    "\n",
    "# lambda x: x[0] + x[1]\n",
    "# elems = (np.array([1, 2, 3], dtype=np.int32), np.array([-1, 1, -1], dtype=np.int32))\n",
    "# alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int32)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(cc, feed_dict={test_user: [1,2,3], test_item: [9,5,6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.product([1,2,3], [4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2672\u001b[0m     \u001b[0;31m# introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, axis, name)\u001b[0m\n\u001b[1;32m   3330\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 3332\u001b[0;31m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   3333\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5646\u001b[0m   \u001b[0;31m#    informative error if a mismatch is found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5647\u001b[0m   \u001b[0moriginal_graph_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5648\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mop_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_input_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5649\u001b[0m     \u001b[0;31m# Determine if this is a valid graph_element.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5650\u001b[0m     \u001b[0;31m# TODO(josh11b): Note that we exclude subclasses of Tensor. Need to clean this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = tf.Variable(tf.random_normal([n_items, n_items], 0.0, 0.01))\n",
    "c_u = np.zeros((n_users, n_items))\n",
    "for u, i in zip(train_user_indices, train_item_indices):\n",
    "    u_items = list(data[u].keys())\n",
    "    c_ij = tf.reduce_sum(tf.gather(tf.gather(c, i), u_items)) / \\\n",
    "           tf.sqrt(tf.cast(tf.size(u_items), tf.float32))\n",
    "    c_u[u, i] = c_ij\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(c_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 2, 3, 4, 5],\n",
       "        [4, 5, 6, 3, 9]], dtype=int32),\n",
       " array([ 5,  7,  9,  7, 14], dtype=int32)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.constant([[1,2,3,4,5], [4,5,6,3,9]])\n",
    "bb = tf.nn.embedding_lookup(aa, [[0,1], [1,1]])\n",
    "user = tf.gather(bb, 0)\n",
    "yj = tf.reduce_sum(user ,axis=0)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run([user, yj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [4, 5, 6]]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = tf.constant([[1,2,3], [4,5,6]])\n",
    "bb = tf.nn.embedding_lookup(aa, [[0,1]])\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding_lookup_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4.],\n",
       "       [5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.arange(10).reshape(2,5).astype(float)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.5, 3.5, 4.5, 5.5, 6.5],\n",
       "       [5. , 6. , 7. , 8. , 9. ],\n",
       "       [5. , 6. , 7. , 8. , 9. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[0,0], [0,0], [1,1], [2,1], [2,2], [2,2]]\n",
    "values = [0,1,1,1,1,1]\n",
    "dense_shape = [2,15]\n",
    "st = tf.SparseTensor(indices, values, dense_shape)\n",
    "# aa = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)\n",
    "bb = tf.nn.embedding_lookup_sparse(aa, st, sp_weights=None)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.]],\n",
       "\n",
       "       [[ 9., 10., 11.],\n",
       "        [12., 13., 14.],\n",
       "        [15., 16., 17.]],\n",
       "\n",
       "       [[18., 19., 20.],\n",
       "        [21., 22., 23.],\n",
       "        [24., 25., 26.]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.arange(27).reshape(3,3,3).astype(float)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[12., 13., 14.],\n",
       "        [15., 16., 17.],\n",
       "        [18., 19., 20.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 9., 10., 11.],\n",
       "        [12., 13., 14.],\n",
       "        [15., 16., 17.]],\n",
       "\n",
       "       [[18., 19., 20.],\n",
       "        [21., 22., 23.],\n",
       "        [24., 25., 26.]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[0,0], [0,1], [0,1], [2,1], [2,2], [3,2]]\n",
    "values = [1,2,1,1,1,2]\n",
    "dense_shape = [2,15]\n",
    "st = tf.SparseTensor(indices, values, dense_shape)\n",
    "# aa = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)\n",
    "bb = tf.nn.embedding_lookup_sparse(aa, st, sp_weights=None)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00455127,  0.01736358, -0.0011284 ,  0.00255089, -0.00957593,\n",
       "         -0.0020925 , -0.01266749, -0.00326786,  0.00396166, -0.00969134,\n",
       "         -0.00675968, -0.00487921, -0.00627048,  0.00205449, -0.00103079,\n",
       "          0.00094458, -0.00496926, -0.0083558 ,  0.00159714, -0.01686201,\n",
       "         -0.00210911, -0.00651083, -0.00908738,  0.01984688,  0.00605965,\n",
       "         -0.01005583, -0.01515545, -0.00346797, -0.00997632, -0.01489756,\n",
       "          0.00344885, -0.00133769,  0.00312323,  0.01420122,  0.01937641,\n",
       "         -0.00676895,  0.00130137,  0.00923016,  0.00342921,  0.00403274,\n",
       "         -0.01719966,  0.00515556,  0.00074134, -0.00503118,  0.00809505,\n",
       "          0.00481872, -0.00567423,  0.00239443,  0.00779041,  0.02053146,\n",
       "          0.00215945,  0.00928877, -0.00847241, -0.00300206, -0.00708658,\n",
       "          0.00164711,  0.00276376,  0.00022526, -0.01156578, -0.00452333,\n",
       "         -0.00070281, -0.00081126, -0.00629355,  0.01388548,  0.02596579,\n",
       "          0.00765122,  0.02379264,  0.01156866, -0.00106809, -0.00255315,\n",
       "         -0.00542865,  0.00573009,  0.00801892,  0.00796182, -0.01034158,\n",
       "          0.00885141,  0.00702093, -0.0042366 , -0.00978541, -0.01893176,\n",
       "          0.00693618,  0.00208274,  0.00870421, -0.00420164, -0.00510583,\n",
       "          0.00431245, -0.00207968, -0.00710661, -0.0006172 , -0.0019692 ,\n",
       "         -0.00108667, -0.01587388,  0.007997  ,  0.0019032 , -0.0006219 ,\n",
       "         -0.00449173,  0.00474171,  0.01039344, -0.00097578, -0.00639347],\n",
       "        [-0.00455127,  0.01736358, -0.0011284 ,  0.00255089, -0.00957593,\n",
       "         -0.0020925 , -0.01266749, -0.00326786,  0.00396166, -0.00969134,\n",
       "         -0.00675968, -0.00487921, -0.00627048,  0.00205449, -0.00103079,\n",
       "          0.00094458, -0.00496926, -0.0083558 ,  0.00159714, -0.01686201,\n",
       "         -0.00210911, -0.00651083, -0.00908738,  0.01984688,  0.00605965,\n",
       "         -0.01005583, -0.01515545, -0.00346797, -0.00997632, -0.01489756,\n",
       "          0.00344885, -0.00133769,  0.00312323,  0.01420122,  0.01937641,\n",
       "         -0.00676895,  0.00130137,  0.00923016,  0.00342921,  0.00403274,\n",
       "         -0.01719966,  0.00515556,  0.00074134, -0.00503118,  0.00809505,\n",
       "          0.00481872, -0.00567423,  0.00239443,  0.00779041,  0.02053146,\n",
       "          0.00215945,  0.00928877, -0.00847241, -0.00300206, -0.00708658,\n",
       "          0.00164711,  0.00276376,  0.00022526, -0.01156578, -0.00452333,\n",
       "         -0.00070281, -0.00081126, -0.00629355,  0.01388548,  0.02596579,\n",
       "          0.00765122,  0.02379264,  0.01156866, -0.00106809, -0.00255315,\n",
       "         -0.00542865,  0.00573009,  0.00801892,  0.00796182, -0.01034158,\n",
       "          0.00885141,  0.00702093, -0.0042366 , -0.00978541, -0.01893176,\n",
       "          0.00693618,  0.00208274,  0.00870421, -0.00420164, -0.00510583,\n",
       "          0.00431245, -0.00207968, -0.00710661, -0.0006172 , -0.0019692 ,\n",
       "         -0.00108667, -0.01587388,  0.007997  ,  0.0019032 , -0.0006219 ,\n",
       "         -0.00449173,  0.00474171,  0.01039344, -0.00097578, -0.00639347],\n",
       "        [-0.00472326, -0.01334624,  0.00548755, -0.00943531, -0.00243722,\n",
       "         -0.00385951,  0.00439932, -0.01738031, -0.00990659, -0.0137385 ,\n",
       "         -0.0028155 ,  0.01502035,  0.00533242, -0.0006885 , -0.00889156,\n",
       "          0.00879662,  0.00685805,  0.00333977,  0.00835315, -0.01135232,\n",
       "         -0.00221364, -0.01648221, -0.00798505,  0.00110527, -0.00833734,\n",
       "          0.00394978,  0.00320985, -0.00896856,  0.00318566,  0.0067419 ,\n",
       "          0.00905036,  0.02431093, -0.00889234,  0.00054242, -0.00990696,\n",
       "          0.00510098, -0.00638029,  0.01396194,  0.00458394, -0.00604428,\n",
       "         -0.00751599,  0.00048757, -0.00612146,  0.00578077, -0.00208263,\n",
       "          0.01246587, -0.01440913, -0.00075256,  0.00774926, -0.01192797,\n",
       "         -0.00507286, -0.01860022,  0.00511476, -0.00741053, -0.01680316,\n",
       "          0.0118481 , -0.01399545, -0.02412163,  0.00443207, -0.00746111,\n",
       "          0.00170914, -0.00955505, -0.01382175, -0.00321057,  0.02560257,\n",
       "          0.00462857, -0.01196908, -0.0002429 ,  0.01152627, -0.00332834,\n",
       "         -0.00553394, -0.00061159,  0.00279375, -0.00220001, -0.00446545,\n",
       "         -0.01584169,  0.00380764, -0.00357322,  0.00941264,  0.00117311,\n",
       "          0.00179284, -0.01261975,  0.01657911, -0.00260486, -0.01486656,\n",
       "          0.01485705,  0.00114793,  0.00132373,  0.01630409,  0.00099097,\n",
       "         -0.00821337, -0.0086867 , -0.01557204, -0.00143044, -0.00437045,\n",
       "          0.00443698,  0.00207294,  0.00583197,  0.01987113, -0.02201726]],\n",
       "       dtype=float32), array([  3, 100], dtype=int32)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = [[] for u in range(n_users)]\n",
    "for u, i, in zip(train_user_indices, train_item_indices):\n",
    "    N[u].append(i)\n",
    "\n",
    "sparse = {'indices': [], 'values': []}\n",
    "for i, user in enumerate(N):\n",
    "    for j, item in enumerate(user):\n",
    "        sparse['indices'].append((i, j))\n",
    "        sparse['values'].append(item)\n",
    "        \n",
    "sparse['dense_shape'] = (n_users, n_items)\n",
    "implicit_feedback = tf.SparseTensor(**sparse)\n",
    "\n",
    "yj = tf.Variable(tf.random_normal([n_items, n_factors], 0.0, 0.01))\n",
    "yjs = tf.nn.embedding_lookup_sparse(yj, implicit_feedback, sp_weights=None, combiner='sqrtn')\n",
    "yju = tf.gather(yjs, [2,2,3])\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run([yju, tf.shape(yju)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding_lookup_sparse - FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [9.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.arange(10).reshape(-1,1).astype(float)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 2.],\n",
       "       [26.]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[0], [0], [1], [2], [2], [2]]\n",
    "values = [0,1,2,3,7,8]\n",
    "dense_shape = [1]\n",
    "st = tf.SparseTensor(indices, values, dense_shape)\n",
    "sw = tf.SparseTensor(indices, [1,2,1,1,1,2], dense_shape)\n",
    "bb = tf.nn.embedding_lookup_sparse(w, st, sp_weights=sw, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse = {'indices': [], 'values': []}\n",
    "for i, sample in enumerate(indices):\n",
    "    for j, ind in enumerate(sample):\n",
    "        sparse['indices'].append((i, j))\n",
    "        sparse['values'].append(ind)\n",
    "        \n",
    "sparse['dense_shape'] = (100, 10)\n",
    "sp_id = tf.SparseTensor(**sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_weight = tf.SparseTensor(sparse['indices'], value.flatten(), sparse['dense_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163],\n",
       "       [165],\n",
       "       [144]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.nn.embedding_lookup_sparse(v, sp_id, sp_weights=sp_weight, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.arange(1000).reshape(100, 10)\n",
    "v[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = np.array([[1, 1, 2], [1, 1, 2], [1, 1, 2]])\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse = {'indices': [], 'values': []}\n",
    "for i, sample in enumerate(indices):\n",
    "    for j, ind in enumerate(sample):\n",
    "        sparse['indices'].append((i, j))\n",
    "        sparse['values'].append(ind)\n",
    "        \n",
    "sparse['dense_shape'] = (100, 10)\n",
    "sp_id = tf.SparseTensor(**sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_sw = {'indices': sparse['indices'], 'values': value.flatten(), 'dense_shape': sparse['dense_shape']}\n",
    "sw = tf.SparseTensor(**sparse_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  33,  36,  39,  42,  45,  48,  51,  54,  57],\n",
       "       [120, 123, 126, 129, 132, 135, 138, 141, 144, 147],\n",
       "       [210, 213, 216, 219, 222, 225, 228, 231, 234, 237]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.nn.embedding_lookup_sparse(v, sp_id, sp_weights=None, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50,  54,  58,  62,  66,  70,  74,  78,  82,  86],\n",
       "       [170, 174, 178, 182, 186, 190, 194, 198, 202, 206],\n",
       "       [290, 294, 298, 302, 306, 310, 314, 318, 322, 326]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.nn.embedding_lookup_sparse(v, sp_id, sp_weights=sw, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.arange(1000).reshape(100, 10)\n",
    "v[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2, 19, 20, 30, 90],\n",
       "       [ 0,  2, 19, 22, 40, 80],\n",
       "       [ 0,  2, 18, 22, 40, 60]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.array([[0, 2, 19, 20, 30, 90], [0, 2, 19, 22, 40, 80], [0, 2, 18, 22, 40, 60]])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 1, 1, 1],\n",
       "       [1, 2, 1, 1, 1, 1],\n",
       "       [1, 2, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = np.array([[1, 2, 1, 1, 1, 1], [1, 2, 1, 1, 1, 1], [1, 2, 1, 1, 1, 1]])\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_indices = tf.placeholder(tf.int64, shape=[None, 6])\n",
    "sparse_indices = tf.placeholder(tf.int64, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse = {'indices': sparse_indices, 'values': tf.reshape(feature_indices, [-1]), 'dense_shape': [1]}\n",
    "tt = tf.SparseTensor(**sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_sw = {'indices': sparse['indices'], 'values': tf.reshape(value, [-1]), 'dense_shape': sparse['dense_shape']}\n",
    "sw = tf.SparseTensor(**sparse_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_sparse_indices(indices):\n",
    "    si = []\n",
    "    for i in range(indices.shape[0]):\n",
    "        si.append(np.zeros([indices.shape[1], 1], dtype=np.int64) + i)\n",
    "    return np.concatenate(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1610, 1616, 1622, 1628, 1634, 1640, 1646, 1652, 1658, 1664],\n",
       "       [1630, 1636, 1642, 1648, 1654, 1660, 1666, 1672, 1678, 1684],\n",
       "       [1420, 1426, 1432, 1438, 1444, 1450, 1456, 1462, 1468, 1474]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.nn.embedding_lookup_sparse(v, tt, sp_weights=None, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(res, {feature_indices: indices, \n",
    "               sparse_indices: build_sparse_indices(indices)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1630, 1637, 1644, 1651, 1658, 1665, 1672, 1679, 1686, 1693],\n",
       "       [1650, 1657, 1664, 1671, 1678, 1685, 1692, 1699, 1706, 1713],\n",
       "       [1440, 1447, 1454, 1461, 1468, 1475, 1482, 1489, 1496, 1503]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = tf.nn.embedding_lookup_sparse(v, tt, sp_weights=sw, combiner=\"sum\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(res, {feature_indices: indices, \n",
    "               sparse_indices: build_sparse_indices(indices)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(6)])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_indices.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - (1, 1, 5)\n",
      "2 - (3, 3, 4)\n",
      "4 - (5, 5, 4)\n",
      "6 - (7, 7, 3)\n",
      "8 - (9, 9, 1)\n",
      "10 - (11, 11, 4)\n",
      "12 - (13, 13, 5)\n",
      "14 - (15, 12, 3)\n",
      "16 - (17, 16, 5)\n",
      "18 - (19, 18, 2)\n",
      "20 - (21, 20, 2)\n",
      "22 - (23, 22, 4)\n",
      "24 - (25, 23, 4)\n",
      "26 - (27, 25, 5)\n",
      "28 - (29, 27, 5)\n",
      "30 - (29, 29, 4)\n",
      "31 - (32, 31, 5)\n",
      "33 - (34, 33, 5)\n",
      "35 - (36, 35, 4)\n",
      "37 - (38, 37, 2)\n",
      "39 - (40, 39, 4)\n",
      "41 - (42, 41, 3)\n",
      "43 - (44, 43, 4)\n",
      "45 - (46, 45, 2)\n",
      "47 - (48, 47, 5)\n",
      "49 - (50, 49, 3)\n",
      "51 - (52, 51, 4)\n",
      "53 - (54, 53, 4)\n",
      "55 - (56, 55, 4)\n",
      "57 - (58, 57, 2)\n",
      "59 - (60, 59, 3)\n",
      "61 - (62, 61, 3)\n",
      "63 - (64, 10, 5)\n",
      "65 - (66, 64, 4)\n",
      "67 - (68, 66, 5)\n",
      "69 - (70, 68, 4)\n",
      "71 - (72, 23, 3)\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_user_indices, \n",
    "                                              train_item_indices, \n",
    "                                              train_ratings))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while 1:\n",
    "            print(sess.run(one_element)[0], '-', sess.run(one_element))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - {'rating': 5, 'item': 1, 'user': 1}\n",
      "2 - {'rating': 4, 'item': 3, 'user': 3}\n",
      "4 - {'rating': 4, 'item': 5, 'user': 5}\n",
      "6 - {'rating': 3, 'item': 7, 'user': 7}\n",
      "8 - {'rating': 1, 'item': 9, 'user': 9}\n",
      "10 - {'rating': 4, 'item': 11, 'user': 11}\n",
      "12 - {'rating': 5, 'item': 13, 'user': 13}\n",
      "14 - {'rating': 3, 'item': 12, 'user': 15}\n",
      "16 - {'rating': 5, 'item': 16, 'user': 17}\n",
      "18 - {'rating': 2, 'item': 18, 'user': 19}\n",
      "20 - {'rating': 2, 'item': 20, 'user': 21}\n",
      "22 - {'rating': 4, 'item': 22, 'user': 23}\n",
      "24 - {'rating': 4, 'item': 23, 'user': 25}\n",
      "26 - {'rating': 5, 'item': 25, 'user': 27}\n",
      "28 - {'rating': 5, 'item': 27, 'user': 29}\n",
      "30 - {'rating': 4, 'item': 29, 'user': 29}\n",
      "31 - {'rating': 5, 'item': 31, 'user': 32}\n",
      "33 - {'rating': 5, 'item': 33, 'user': 34}\n",
      "35 - {'rating': 4, 'item': 35, 'user': 36}\n",
      "37 - {'rating': 2, 'item': 37, 'user': 38}\n",
      "39 - {'rating': 4, 'item': 39, 'user': 40}\n",
      "41 - {'rating': 3, 'item': 41, 'user': 42}\n",
      "43 - {'rating': 4, 'item': 43, 'user': 44}\n",
      "45 - {'rating': 2, 'item': 45, 'user': 46}\n",
      "47 - {'rating': 5, 'item': 47, 'user': 48}\n",
      "49 - {'rating': 3, 'item': 49, 'user': 50}\n",
      "51 - {'rating': 4, 'item': 51, 'user': 52}\n",
      "53 - {'rating': 4, 'item': 53, 'user': 54}\n",
      "55 - {'rating': 4, 'item': 55, 'user': 56}\n",
      "57 - {'rating': 2, 'item': 57, 'user': 58}\n",
      "59 - {'rating': 3, 'item': 59, 'user': 60}\n",
      "61 - {'rating': 3, 'item': 61, 'user': 62}\n",
      "63 - {'rating': 5, 'item': 10, 'user': 64}\n",
      "65 - {'rating': 4, 'item': 64, 'user': 66}\n",
      "67 - {'rating': 5, 'item': 66, 'user': 68}\n",
      "69 - {'rating': 4, 'item': 68, 'user': 70}\n",
      "71 - {'rating': 3, 'item': 23, 'user': 72}\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"user\": train_user_indices, \n",
    "        \"item\": train_item_indices, \n",
    "        \"rating\": train_ratings\n",
    "    })\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while 1:\n",
    "            print(sess.run(one_element)[\"user\"], '-', sess.run(one_element))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': array([51, 63, 58, 42, 65, 27, 46, 29, 71, 60], dtype=int32), 'rating': array([3, 1, 2, 3, 3, 5, 2, 5, 4, 3], dtype=int32), 'item': array([50, 62, 57, 41, 63, 25, 45, 27, 61, 59], dtype=int32)}\n",
      "{'user': array([48, 55, 32, 29, 30, 26, 68, 69, 37,  8], dtype=int32), 'rating': array([5, 3, 5, 4, 4, 5, 5, 2, 5, 1], dtype=int32), 'item': array([47, 54, 31, 29, 28, 24, 66, 67, 36,  8], dtype=int32)}\n",
      "{'user': array([ 5, 31, 57, 24, 21, 25, 33, 36, 44, 49], dtype=int32), 'rating': array([4, 2, 5, 4, 2, 4, 5, 4, 4, 4], dtype=int32), 'item': array([ 5, 30, 56, 13, 20, 23, 32, 35, 43, 48], dtype=int32)}\n",
      "{'user': array([40, 28, 47, 13, 61, 11, 41, 45, 18, 12], dtype=int32), 'rating': array([4, 5, 5, 5, 5, 4, 5, 1, 2, 4], dtype=int32), 'item': array([39, 26, 46, 13, 60, 11, 40, 44, 17, 12], dtype=int32)}\n",
      "{'user': array([ 2, 20, 52, 35, 16, 73, 38, 15,  3,  7], dtype=int32), 'rating': array([4, 5, 4, 3, 4, 4, 2, 3, 4, 3], dtype=int32), 'item': array([ 2, 19, 51, 34, 15, 69, 37, 12,  3,  7], dtype=int32)}\n",
      "{'user': array([62, 34, 19,  6, 72,  1, 66,  9, 10, 43], dtype=int32), 'rating': array([3, 5, 2, 5, 3, 5, 4, 1, 3, 3], dtype=int32), 'item': array([61, 33, 18,  6, 23,  1, 64,  9, 10, 42], dtype=int32)}\n",
      "{'user': array([14, 39, 70, 53, 64, 50,  0, 59, 22, 17], dtype=int32), 'rating': array([3, 4, 4, 5, 5, 3, 2, 3, 5, 5], dtype=int32), 'item': array([14, 38, 68, 52, 10, 49,  0, 58, 21, 16], dtype=int32)}\n",
      "{'user': array([54, 23,  4, 56, 67], dtype=int32), 'rating': array([4, 4, 1, 4, 5], dtype=int32), 'item': array([53, 22,  4, 55, 65], dtype=int32)}\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"user\": train_user_indices, \n",
    "        \"item\": train_item_indices, \n",
    "        \"rating\": train_ratings\n",
    "    })\n",
    "dataset = dataset.shuffle(100).batch(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while 1:\n",
    "            print(sess.run(one_element))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': array([64, 13, 69, 49,  1, 22, 10, 12, 23, 16, 59, 23, 57, 41, 44, 37]),\n",
      " 'rating': array([4, 4, 4, 3, 5, 4, 3, 4, 3, 5, 3, 4, 2, 3, 1, 2]),\n",
      " 'user': array([66, 24, 73, 50,  1, 23, 10, 12, 72, 17, 60, 25, 58, 42, 45, 38])}\n",
      "{'item': array([19, 38, 39, 43, 15, 26,  3, 35, 42, 17, 52, 60, 34, 11, 54, 47]),\n",
      " 'rating': array([5, 4, 4, 4, 4, 5, 4, 4, 3, 2, 5, 5, 3, 4, 3, 5]),\n",
      " 'user': array([20, 39, 40, 44, 16, 28,  3, 36, 43, 18, 53, 61, 35, 11, 55, 48])}\n",
      "{'item': array([18, 58, 46, 63, 67, 25, 20, 30, 50, 61,  7, 32, 14, 56, 68, 55]),\n",
      " 'rating': array([2, 3, 5, 3, 2, 5, 2, 2, 3, 3, 3, 5, 3, 5, 4, 4]),\n",
      " 'user': array([19, 59, 47, 65, 69, 27, 21, 31, 51, 62,  7, 33, 14, 57, 70, 56])}\n",
      "{'item': array([24, 66, 61, 53, 12, 29,  8, 13, 45, 27,  4,  9, 36, 31,  6,  5]),\n",
      " 'rating': array([5, 5, 4, 4, 3, 4, 1, 5, 2, 5, 1, 1, 5, 5, 5, 4]),\n",
      " 'user': array([26, 68, 71, 54, 15, 29,  8, 13, 46, 29,  4,  9, 37, 32,  6,  5])}\n",
      "{'item': array([28, 65, 10, 33, 40,  0,  2, 21, 48, 62, 51]),\n",
      " 'rating': array([4, 5, 5, 5, 5, 2, 4, 5, 4, 1, 4]),\n",
      " 'user': array([30, 67, 64, 34, 41,  0,  2, 22, 49, 63, 52])}\n",
      "{'item': array([23, 25, 11,  8, 34, 31,  7, 53, 30, 39, 49, 36, 66, 16, 10, 61]),\n",
      " 'rating': array([4, 5, 4, 1, 3, 5, 3, 4, 2, 4, 3, 5, 5, 5, 5, 3]),\n",
      " 'user': array([25, 27, 11,  8, 35, 32,  7, 54, 31, 40, 50, 37, 68, 17, 64, 62])}\n",
      "{'item': array([ 2, 23, 45, 68, 37,  5, 20, 38, 47, 18,  0, 56, 55, 64, 41, 54]),\n",
      " 'rating': array([4, 3, 2, 4, 2, 4, 2, 4, 5, 2, 2, 5, 4, 4, 3, 3]),\n",
      " 'user': array([ 2, 72, 46, 70, 38,  5, 21, 39, 48, 19,  0, 57, 56, 66, 42, 55])}\n",
      "{'item': array([51, 26,  3, 67, 43, 50, 27, 35, 60,  1, 14, 63, 32, 24, 10, 46]),\n",
      " 'rating': array([4, 5, 4, 2, 4, 3, 5, 4, 5, 5, 3, 3, 5, 5, 3, 5]),\n",
      " 'user': array([52, 28,  3, 69, 44, 51, 29, 36, 61,  1, 14, 65, 33, 26, 10, 47])}\n",
      "{'item': array([29, 12, 62, 21, 42, 19, 48, 28, 22, 12, 52, 65,  6, 59, 13, 13]),\n",
      " 'rating': array([4, 3, 1, 5, 3, 5, 4, 4, 4, 4, 5, 5, 5, 3, 5, 4]),\n",
      " 'user': array([29, 15, 63, 22, 43, 20, 49, 30, 23, 12, 53, 67,  6, 60, 13, 24])}\n",
      "{'item': array([ 9, 33, 40, 57, 17, 61, 58, 69, 15,  4, 44]),\n",
      " 'rating': array([1, 5, 5, 2, 2, 4, 3, 4, 4, 1, 1]),\n",
      " 'user': array([ 9, 34, 41, 58, 18, 71, 59, 73, 16,  4, 45])}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'user': train_user_indices, \n",
    "                                              'item': train_item_indices, \n",
    "                                              'rating': train_ratings})\n",
    "dataset = dataset.shuffle(len(train_ratings)).batch(16).repeat(2)\n",
    "iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "batch = iterator.get_next()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(iterator.make_initializer(dataset))\n",
    "try:\n",
    "    while True:\n",
    "        pprint.pprint(sess.run(batch))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while 1:\n",
    "            print(sess.run(one_element))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"a\": np.array([1.0, 2.0, 3.0, 4.0, 5.0]), \n",
    "        \"b\": np.random.uniform(size=(5,2))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': tf.float64, 'b': tf.float64},\n",
       " {'a': TensorShape([]), 'b': TensorShape([Dimension(2)])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.output_types, dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.83989501, 0.6755826 ]), 2.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([4.0, 2.0, 3.0])\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run([one_element['b'], tf.gather(c, tf.cast(one_element['a'], tf.int32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "dataset = dataset.map(lambda x: x + 2)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "sess = tf.InteractiveSession()\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(one_element))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40  4 87 58 84 79 93 90 24  6 88 32 43 36 53 81 31 14 45 52 12 61 21 85\n",
      " 38 22 20 69 29 65 17 44]\n",
      "[92  9 73 62  2  5 10 82 68 25 37 13 49 57 89 18 95 46 48 33 72 86 63 26\n",
      " 91  8  7 56 51 41 11 94]\n",
      "[55 16 47 35 15 50 39 19 23 74  1 34 60 76 77 66 75  0 30 59 28 78  3 67\n",
      " 70 80 42 71 54 83 64 27]\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.random.permutation(np.arange(32*3)))\n",
    "dataset = dataset.batch(32)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "sess = tf.InteractiveSession()\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(one_element))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"End!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(start=0, limit=limit))\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={limit: 10})\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        assert i == value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': tf.float32, 'b': tf.int32}\n",
      "{'a': TensorShape([]), 'b': TensorShape([Dimension(100)])}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    {\"a\": tf.random_uniform([4]), \n",
    "     \"b\": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "2 10\n",
      "4 20\n",
      "6 30\n",
      "8 40\n",
      "10 50\n",
      "12 60\n",
      "14 70\n",
      "16 80\n",
      "18 90\n",
      "0 0\n",
      "2 10\n",
      "4 20\n",
      "6 30\n",
      "8 40\n",
      "10 50\n",
      "12 60\n",
      "14 70\n",
      "16 80\n",
      "18 90\n",
      "0 0\n",
      "2 10\n",
      "4 20\n",
      "6 30\n",
      "8 40\n",
      "10 50\n",
      "12 60\n",
      "14 70\n",
      "16 80\n",
      "18 90\n"
     ]
    }
   ],
   "source": [
    "iterator = tf.data.Iterator.from_structure(tf.int64, tf.TensorShape([]))\n",
    "dataset_range = tf.data.Dataset.range(10)\n",
    "range_initializer = iterator.make_initializer(dataset_range)\n",
    "dataset_evens = dataset_range.filter(lambda x: x % 2 == 0)\n",
    "evens_initializer = iterator.make_initializer(dataset_evens)\n",
    "\n",
    "def model_fn(a):\n",
    "    return a * 2, a * 10\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "prediction, loss = model_fn(iterator.get_next())\n",
    "for _ in range(3):\n",
    "    sess.run(range_initializer)  ####\n",
    "    while True:\n",
    "        try:\n",
    "            pred, loss_val = sess.run([prediction, loss])\n",
    "            print(pred, loss_val)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    sess.run(evens_initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            pred, loss_val = sess.run([prediction, loss])\n",
    "            print(\"twooooo\")\n",
    "            print(pred, loss_val)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2] [ 0 10]\n",
      "[4 6] [20 30]\n",
      "[ 8 10] [40 50]\n",
      "[12 14] [60 70]\n",
      "[16 18] [80 90]\n"
     ]
    }
   ],
   "source": [
    "#　iterator = tf.data.Iterator.from_structure(tf.int32, tf.TensorShape([None]))\n",
    "# dataset_range = tf.data.Dataset.range(10)\n",
    "\n",
    "dataset_range = tf.data.Dataset.from_tensor_slices(np.arange(10, dtype=np.int32))\n",
    "dataset_range = dataset_range.batch(2)\n",
    "iterator = tf.data.Iterator.from_structure(dataset_range.output_types, dataset_range.output_shapes)\n",
    "range_initializer = iterator.make_initializer(dataset_range)\n",
    "dataset_evens = dataset_range.filter(lambda x: x % 2 == 0)\n",
    "evens_initializer = iterator.make_initializer(dataset_evens)\n",
    "\n",
    "def model_fn(a):\n",
    "    return a * 2, a * 10\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "prediction, loss = model_fn(iterator.get_next())\n",
    "for _ in range(1):\n",
    "    sess.run(range_initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            pred, loss_val = sess.run([prediction, loss])\n",
    "            print(pred, loss_val)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    sess.run(evens_initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            pred, loss_val = sess.run([prediction, loss])\n",
    "            print(\"twooooo\")\n",
    "            print(pred, loss_val)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "sess.run(iterator.initializer, feed_dict={max_value: 10})\n",
    "for i in range(10):\n",
    "    value = sess.run(next_element)\n",
    "    assert i == value\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## FeatureBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureBuilder:\n",
    "    def __init__(self, value_sharing=False, include_user_item=True,\n",
    "                 n_users=None, n_items=None):\n",
    "        self.value_sharing = value_sharing\n",
    "        self.include_user_item = include_user_item\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "\n",
    "    def fit(self, categorical_features, numerical_features, train_size,\n",
    "            user_features=None, item_features=None):\n",
    "        self.total_count = 0  # add user & item indices before/after\n",
    "        feature_indices = []\n",
    "        feature_values = []\n",
    "        for k, v in numerical_features.items():\n",
    "            feature_indices.append([self.total_count] * train_size)\n",
    "            feature_values.append(v)\n",
    "            self.total_count += 1\n",
    "\n",
    "        self.val_index_dict = defaultdict(dict)\n",
    "        for k, v in categorical_features.items():\n",
    "            unique_vals, indices = np.unique(v, return_inverse=True)\n",
    "            unique_vals_length = len(unique_vals)\n",
    "            indices += self.total_count\n",
    "            self.val_index_dict[k].update(zip(unique_vals, np.unique(indices)))\n",
    "            feature_indices.append(indices.tolist())\n",
    "            feature_values.append([1.0] * train_size)\n",
    "            self.total_count += unique_vals_length\n",
    "\n",
    "        self.feature_size = self.total_count  # preserve total_count for transform function\n",
    "        if self.include_user_item:\n",
    "            feature_indices.append(user_features + self.feature_size)\n",
    "            self.feature_size += self.n_users\n",
    "            feature_indices.append(item_features + self.feature_size)\n",
    "            self.feature_size += self.n_items\n",
    "            feature_values.append([1.0] * train_size)\n",
    "            feature_values.append([1.0] * train_size)\n",
    "\n",
    "        feature_indices = np.array(feature_indices).T.astype(np.int32)\n",
    "        feature_values = np.array(feature_values).T.astype(np.float32)\n",
    "        return feature_indices, feature_values, self.feature_size\n",
    "\n",
    "    def transform(self, test_cat_feat, test_num_feat, test_size,\n",
    "                  test_user_features=None, test_item_features=None):\n",
    "        test_feature_indices = []\n",
    "        test_feature_values = []\n",
    "        test_total_count = 0\n",
    "        for k, v in test_num_feat.items():\n",
    "            test_feature_indices.append([test_total_count] * test_size)\n",
    "            test_feature_values.append(v)\n",
    "            test_total_count += 1\n",
    "\n",
    "        for k, v in test_cat_feat.items():\n",
    "            indices = pd.Series(v).map(self.val_index_dict[k])\n",
    "            indices = indices.fillna(self.feature_size)\n",
    "            test_feature_indices.append(indices.tolist())\n",
    "            test_feature_values.append([1.0] * test_size)\n",
    "\n",
    "        if self.include_user_item:\n",
    "            test_feature_indices.append(test_user_features + self.total_count)\n",
    "            test_feature_indices.append(test_item_features + self.total_count + self.n_users)\n",
    "            test_feature_values.append([1.0] * test_size)\n",
    "            test_feature_values.append([1.0] * test_size)\n",
    "\n",
    "        test_feature_indices = np.array(test_feature_indices).T.astype(np.int32)\n",
    "        test_feature_values = np.array(test_feature_values).T.astype(np.float32)\n",
    "        return test_feature_indices, test_feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = {3: ['a', 'b', 'c'], 4: ['b', 'b', 'd']}\n",
    "nn = {0: [1, 2, 3], 1: [4, 5, 6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc2 = {3: ['a', 'b', 'a', 'r', 'q'], 4: ['d', 'b', 'd', 's', 'z']}\n",
    "nn2 = {0: [1, 3, 3, 4, 5], 1: [4, 5, 6, 6, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uff = np.array([100, 200, 300])\n",
    "iff = np.array([50, 100, 200])\n",
    "n_users = 400\n",
    "n_items = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uff2 = np.array([0,1,2,3,4])\n",
    "iff2 = np.array([0,1,2,3,700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb = FeatureBuilder(n_users=n_users, n_items=n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi, fv, fs = fb.fit(cc, nn, 3, uff, iff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   5, 107, 457],\n",
       "       [  0,   1,   3,   5, 207, 507],\n",
       "       [  0,   1,   4,   6, 307, 607]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 1., 1., 1., 1.],\n",
       "       [2., 5., 1., 1., 1., 1.],\n",
       "       [3., 6., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi2, fv2 = fb.transform(cc2, nn2, 5, uff2, iff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2,    6,    7,  407],\n",
       "       [   0,    1,    3,    5,    8,  408],\n",
       "       [   0,    1,    2,    6,    9,  409],\n",
       "       [   0,    1, 1007, 1007,   10,  410],\n",
       "       [   0,    1, 1007, 1007,   11, 1107]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 1., 1., 1., 1.],\n",
       "       [3., 5., 1., 1., 1., 1.],\n",
       "       [3., 6., 1., 1., 1., 1.],\n",
       "       [4., 6., 1., 1., 1., 1.],\n",
       "       [5., 4., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, include_features=False):\n",
    "        self.train_user = defaultdict(dict)\n",
    "        self.train_item = defaultdict(dict)\n",
    "        self.user2id = dict()\n",
    "        self.item2id = dict()\n",
    "        self.id2user = dict()\n",
    "        self.id2item = dict()\n",
    "        self.train_user_indices = list()\n",
    "        self.train_item_indices = list()\n",
    "        self.train_labels = list()\n",
    "        self.test_user_indices = list()\n",
    "        self.test_item_indices = list()\n",
    "        self.test_labels = list()\n",
    "        self.include_features = include_features\n",
    "        if self.include_features:\n",
    "            self.train_categorical_features = defaultdict(list)\n",
    "            self.train_numerical_features = defaultdict(list)\n",
    "            self.test_categorical_features = defaultdict(list)\n",
    "            self.test_numerical_features = defaultdict(list)\n",
    "\n",
    "    def _get_pool(self, data_path=\"../ml-1m/ratings.dat\", shuffle=True, length=\"all\",\n",
    "                    train_frac=0.8, sep=\",\", user_col=None, item_col=None, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        user_pool = set()\n",
    "        item_pool = set()\n",
    "        loaded_data = open(data_path, 'r').readlines()\n",
    "        if shuffle:\n",
    "            loaded_data = np.random.permutation(loaded_data)\n",
    "        if length == \"all\":\n",
    "            length = len(loaded_data)\n",
    "        for i, data in enumerate(loaded_data[:length]):\n",
    "            line = data.split(sep)\n",
    "            user = line[user_col]\n",
    "            item = line[item_col]\n",
    "            if i <= int(train_frac * length):\n",
    "                user_pool.add(user)\n",
    "                item_pool.add(item)\n",
    "        return user_pool, item_pool, loaded_data\n",
    "\n",
    "    def build_dataset(self, data_path=\"../ml-1m/ratings.dat\", shuffle=True, length=\"all\",\n",
    "                      train_frac=0.8, implicit_label=False, build_negative=False, seed=42,\n",
    "                      num_neg=None, sep=\",\", user_col=None, item_col=None, label_col=None,\n",
    "                      numerical_col=None, categorical_col=None):  # numerical feature 不做 embedding\n",
    "        user_pool, item_pool, loaded_data = self._get_pool(data_path=data_path,\n",
    "                                                             shuffle=shuffle,\n",
    "                                                             length=length,\n",
    "                                                             train_frac=train_frac,\n",
    "                                                             sep=sep,\n",
    "                                                             user_col=user_col,\n",
    "                                                             item_col=item_col,\n",
    "                                                             seed=seed)\n",
    "\n",
    "        index_user = 0\n",
    "        index_item = 0\n",
    "        if length == \"all\":\n",
    "            length = len(loaded_data)\n",
    "        for i, data in enumerate(loaded_data[:length]):\n",
    "            line = data.split(sep)\n",
    "            user = line[user_col]\n",
    "            item = line[item_col]\n",
    "            label = line[label_col]\n",
    "            try:\n",
    "                user_id = self.user2id[user]\n",
    "            except KeyError:\n",
    "                user_id = index_user\n",
    "                self.user2id[user] = index_user\n",
    "                index_user += 1\n",
    "            try:\n",
    "                item_id = self.item2id[item]\n",
    "            except KeyError:\n",
    "                item_id = index_item\n",
    "                self.item2id[item] = index_item\n",
    "                index_item += 1\n",
    "\n",
    "            if user not in user_pool or item not in item_pool:\n",
    "                continue\n",
    "\n",
    "            elif i <= int(train_frac * length):\n",
    "                self.train_user_indices.append(user_id)\n",
    "                self.train_item_indices.append(item_id)\n",
    "                self.train_labels.append(int(label))\n",
    "                self.train_user[user_id].update(dict(zip([item_id], [int(label)])))\n",
    "                self.train_item[item_id].update(dict(zip([user_id], [int(label)])))\n",
    "\n",
    "                if categorical_col is not None and self.include_features:\n",
    "                    for cat_feat in categorical_col:\n",
    "                        self.train_categorical_features[cat_feat].append(line[cat_feat])\n",
    "\n",
    "                if numerical_col is not None and self.include_features:\n",
    "                    for num_feat in numerical_col:\n",
    "                        self.train_numerical_features[num_feat].append(line[num_feat])\n",
    "\n",
    "            else:\n",
    "                self.test_user_indices.append(user_id)\n",
    "                self.test_item_indices.append(item_id)\n",
    "                self.test_labels.append(int(label))\n",
    "\n",
    "                if categorical_col is not None and self.include_features:\n",
    "                    for cat_feat in categorical_col:\n",
    "                        self.test_categorical_features[cat_feat].append(line[cat_feat])\n",
    "\n",
    "                if numerical_col is not None and self.include_features:\n",
    "                    for num_feat in numerical_col:\n",
    "                        self.test_numerical_features[num_feat].append(line[num_feat])\n",
    "\n",
    "        self.train_user_indices = np.array(self.train_user_indices)\n",
    "        self.train_item_indices = np.array(self.train_item_indices)\n",
    "        self.train_labels = np.array(self.train_labels)\n",
    "        if self.include_features:\n",
    "            fb = FeatureBuilder(include_user_item=True, n_users=self.n_users, n_items=self.n_items)\n",
    "            self.train_feat_indices, self.train_feat_values, self.feature_size = \\\n",
    "                fb.fit(self.train_categorical_features,\n",
    "                       self.train_numerical_features,\n",
    "                       len(self.train_labels),\n",
    "                       self.train_user_indices,\n",
    "                       self.train_item_indices)\n",
    "\n",
    "        # user_embedding, item_embedding, feature_embedding\n",
    "        # np.unique(return_inverse=True)\n",
    "        # numerical min_max_scale\n",
    "        # min_occurance\n",
    "\n",
    "        if implicit_label:\n",
    "            self.train_labels = np.ones(len(self.train_labels), dtype=np.float32)\n",
    "\n",
    "        if build_negative:\n",
    "            self.build_trainset_implicit(num_neg)\n",
    "\n",
    "        print(\"testset size before: \", len(self.test_labels))\n",
    "    #    test_all = np.concatenate([np.expand_dims(self.test_user_indices, 1),\n",
    "    #                               np.expand_dims(self.test_item_indices, 1),\n",
    "    #                               np.expand_dims(self.test_labels, 1)],\n",
    "    #                               axis=1)\n",
    "    #    test_safe = test_all[(test_all[:, 0] < self.n_users) & (test_all[:, 1] < self.n_items)]\n",
    "    #    test_danger = test_all[(test_all[:, 0] >= self.n_users) & (test_all[:, 1] >= self.n_items)]\n",
    "    #    self.test_user_indices = test_safe[:, 0]\n",
    "    #    self.test_item_indices = test_safe[:, 1]\n",
    "    #    self.test_labels = test_safe[:, 2]\n",
    "\n",
    "        self.test_user_indices = np.array(self.test_user_indices)\n",
    "        self.test_item_indices = np.array(self.test_item_indices)\n",
    "        self.test_labels = np.array(self.test_labels)\n",
    "        if self.include_features:\n",
    "            self.test_feat_indices, self.test_feat_values = \\\n",
    "                fb.transform(self.test_categorical_features,\n",
    "                       self.test_numerical_features,\n",
    "                       len(self.test_labels),\n",
    "                       self.test_user_indices,\n",
    "                       self.test_item_indices)\n",
    "\n",
    "        if implicit_label:\n",
    "            self.test_labels = np.ones(len(self.test_labels), dtype=np.float32)\n",
    "\n",
    "        if build_negative:\n",
    "            self.build_testset_implicit(num_neg)\n",
    "    #        self.neg = negative_sampling(self, 4, self.batch_size)\n",
    "        #    self.build_trainset_implicit()\n",
    "        #    self.build_testset_implicit()\n",
    "        print(\"testset size after: \", len(self.test_labels))\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def n_users(self):\n",
    "        return len(self.train_user)\n",
    "\n",
    "    @property\n",
    "    def n_items(self):\n",
    "        return len(self.train_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", header=None, names=['user', 'item', 'rating','timestamp'])\n",
    "users = pd.read_csv(\"./ml-1m/users.dat\", sep=\"::\", header=None, names=['user', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "movies = pd.read_csv(\"./ml-1m/movies.dat\", sep=\"::\", header=None, names=['item', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1  1193       5  978300760\n",
       "1     1   661       3  978302109\n",
       "2     1   914       3  978301968\n",
       "3     1  3408       4  978300275\n",
       "4     1  2355       5  978824291"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user gender  age  occupation zipcode\n",
       "0     1      F    1          10   48067\n",
       "1     2      M   56          16   70072\n",
       "2     3      M   25          15   55117\n",
       "3     4      M   45           7   02460\n",
       "4     5      M   25          20   55455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item                               title                        genres\n",
       "0     1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1     2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2     3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3     4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4     5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Animation|Children's|Comedy\", \"Adventure|Children's|Fantasy\",\n",
       "       'Comedy|Romance', 'Comedy|Drama', 'Comedy',\n",
       "       'Action|Crime|Thriller', \"Adventure|Children's\", 'Action',\n",
       "       'Action|Adventure|Thriller', 'Comedy|Drama|Romance',\n",
       "       'Comedy|Horror', \"Animation|Children's\", 'Drama',\n",
       "       'Action|Adventure|Romance', 'Drama|Thriller', 'Drama|Romance',\n",
       "       'Thriller', 'Action|Comedy|Drama', 'Crime|Drama|Thriller',\n",
       "       'Drama|Sci-Fi', 'Romance', 'Adventure|Sci-Fi', 'Adventure|Romance',\n",
       "       \"Children's|Comedy|Drama\", 'Documentary', 'Drama|War',\n",
       "       'Action|Crime|Drama', 'Action|Adventure', 'Crime|Thriller',\n",
       "       \"Animation|Children's|Musical|Romance\", 'Action|Drama|Thriller',\n",
       "       \"Children's|Comedy\", 'Drama|Mystery', 'Sci-Fi|Thriller',\n",
       "       'Action|Comedy|Crime|Horror|Thriller', 'Drama|Musical',\n",
       "       'Crime|Drama|Romance', 'Adventure|Drama', 'Action|Thriller',\n",
       "       \"Adventure|Children's|Comedy|Musical\", 'Action|Drama|War',\n",
       "       'Action|Adventure|Crime', 'Crime', 'Drama|Mystery|Romance',\n",
       "       'Action|Drama', 'Drama|Romance|War', 'Horror',\n",
       "       'Action|Adventure|Comedy|Crime', 'Comedy|War',\n",
       "       'Action|Adventure|Mystery|Sci-Fi', 'Drama|Thriller|War',\n",
       "       'Action|Romance|Thriller', 'Crime|Film-Noir|Mystery|Thriller',\n",
       "       'Action|Adventure|Drama|Romance', \"Adventure|Children's|Drama\",\n",
       "       'Action|Sci-Fi|Thriller', 'Action|Adventure|Sci-Fi',\n",
       "       \"Action|Children's\", 'Horror|Sci-Fi', 'Action|Crime|Sci-Fi',\n",
       "       'Western', \"Animation|Children's|Comedy|Romance\",\n",
       "       \"Children's|Drama\", 'Crime|Drama',\n",
       "       'Drama|Fantasy|Romance|Thriller', 'Drama|Horror', 'Comedy|Sci-Fi',\n",
       "       'Mystery|Thriller', \"Adventure|Children's|Comedy|Fantasy|Romance\",\n",
       "       'Action|Adventure|Fantasy|Sci-Fi', 'Drama|Romance|War|Western',\n",
       "       'Action|Crime', 'Crime|Drama|Romance|Thriller',\n",
       "       'Action|Adventure|Western', 'Horror|Thriller',\n",
       "       \"Children's|Comedy|Fantasy\", 'Film-Noir|Thriller',\n",
       "       'Action|Comedy|Musical|Sci-Fi', \"Children's\",\n",
       "       'Drama|Mystery|Thriller', 'Comedy|Romance|War', 'Action|Comedy',\n",
       "       \"Adventure|Children's|Romance\", \"Animation|Children's|Musical\",\n",
       "       'Comedy|Crime|Fantasy', 'Action|Comedy|Western', 'Action|Sci-Fi',\n",
       "       'Action|Adventure|Comedy|Romance', 'Comedy|Crime|Drama',\n",
       "       'Comedy|Thriller', 'Horror|Sci-Fi|Thriller',\n",
       "       'Mystery|Romance|Thriller', 'Comedy|Western', 'Drama|Western',\n",
       "       'Action|Adventure|Crime|Thriller', 'Action|Comedy|War',\n",
       "       'Comedy|Mystery', 'Comedy|Mystery|Romance', 'Comedy|Drama|War',\n",
       "       'Action|Drama|Mystery', 'Comedy|Crime|Horror', 'Film-Noir|Sci-Fi',\n",
       "       'Comedy|Romance|Thriller', \"Action|Adventure|Children's|Sci-Fi\",\n",
       "       \"Children's|Comedy|Musical\", 'Action|Adventure|Comedy',\n",
       "       'Action|Crime|Romance',\n",
       "       \"Action|Adventure|Animation|Children's|Fantasy\",\n",
       "       \"Animation|Children's|Comedy|Musical\", 'Adventure|Drama|Western',\n",
       "       'Action|Adventure|Crime|Drama',\n",
       "       'Action|Adventure|Animation|Horror|Sci-Fi', 'Action|Horror|Sci-Fi',\n",
       "       'War', 'Action|Adventure|Mystery', 'Mystery',\n",
       "       'Action|Adventure|Fantasy',\n",
       "       \"Adventure|Animation|Children's|Comedy|Fantasy\", 'Sci-Fi',\n",
       "       'Documentary|Drama', 'Action|Adventure|Comedy|War',\n",
       "       'Crime|Film-Noir|Thriller', 'Animation',\n",
       "       'Action|Adventure|Romance|Thriller', 'Animation|Sci-Fi',\n",
       "       'Animation|Comedy|Thriller', 'Film-Noir', 'Sci-Fi|War',\n",
       "       'Adventure', 'Comedy|Crime', 'Action|Sci-Fi|War',\n",
       "       'Comedy|Fantasy|Romance|Sci-Fi', 'Fantasy',\n",
       "       'Action|Mystery|Thriller', 'Comedy|Musical',\n",
       "       'Action|Adventure|Sci-Fi|Thriller', \"Children's|Drama|Fantasy\",\n",
       "       'Adventure|War', 'Musical|Romance', 'Comedy|Musical|Romance',\n",
       "       'Comedy|Mystery|Romance|Thriller', 'Film-Noir|Mystery', 'Musical',\n",
       "       \"Adventure|Children's|Drama|Musical\",\n",
       "       'Drama|Mystery|Sci-Fi|Thriller', 'Romance|Thriller',\n",
       "       'Film-Noir|Romance|Thriller', 'Crime|Film-Noir|Mystery',\n",
       "       'Adventure|Comedy', 'Action|Adventure|Romance|War', 'Romance|War',\n",
       "       'Action|Drama|Western', \"Children's|Comedy|Western\",\n",
       "       \"Adventure|Children's|Comedy\", \"Children's|Comedy|Mystery\",\n",
       "       \"Adventure|Children's|Fantasy|Sci-Fi\",\n",
       "       \"Adventure|Animation|Children's|Musical\",\n",
       "       \"Adventure|Children's|Musical\", 'Crime|Film-Noir',\n",
       "       \"Adventure|Children's|Comedy|Fantasy\",\n",
       "       \"Children's|Drama|Fantasy|Sci-Fi\", 'Action|Romance',\n",
       "       'Adventure|Western', 'Comedy|Fantasy', 'Animation|Comedy',\n",
       "       'Crime|Drama|Film-Noir', 'Action|Adventure|Drama|Sci-Fi|War',\n",
       "       'Action|Sci-Fi|Thriller|War', 'Action|Western',\n",
       "       \"Action|Animation|Children's|Sci-Fi|Thriller|War\",\n",
       "       'Action|Adventure|Romance|Sci-Fi|War',\n",
       "       'Action|Horror|Sci-Fi|Thriller',\n",
       "       'Action|Adventure|Comedy|Horror|Sci-Fi', 'Action|Comedy|Musical',\n",
       "       'Mystery|Sci-Fi', 'Film-Noir|Mystery|Thriller',\n",
       "       'Adventure|Comedy|Drama', 'Action|Adventure|Comedy|Horror',\n",
       "       'Action|Drama|Mystery|Romance|Thriller', 'Comedy|Mystery|Thriller',\n",
       "       'Adventure|Animation|Sci-Fi|Thriller', 'Action|Drama|Romance',\n",
       "       'Action|Adventure|Drama', 'Comedy|Drama|Musical',\n",
       "       'Documentary|War', 'Drama|Musical|War', 'Action|Horror',\n",
       "       'Horror|Romance', 'Action|Comedy|Sci-Fi|War', 'Crime|Drama|Sci-Fi',\n",
       "       'Action|Romance|War', 'Action|Comedy|Crime|Drama',\n",
       "       'Action|Drama|Thriller|War', \"Action|Adventure|Children's\",\n",
       "       \"Action|Adventure|Children's|Fantasy\",\n",
       "       \"Adventure|Animation|Children's|Comedy|Musical\",\n",
       "       'Crime|Drama|Mystery', 'Action|Adventure|Comedy|Sci-Fi',\n",
       "       \"Children's|Fantasy\", 'Action|Mystery|Sci-Fi|Thriller',\n",
       "       'Action|Mystery|Romance|Thriller', 'Adventure|Thriller',\n",
       "       'Action|Thriller|War', 'Action|Crime|Mystery',\n",
       "       'Horror|Mystery|Thriller', 'Crime|Horror|Mystery|Thriller',\n",
       "       'Comedy|Drama|Thriller', 'Drama|Sci-Fi|Thriller',\n",
       "       'Drama|Romance|Thriller', 'Action|Adventure|Sci-Fi|War',\n",
       "       'Comedy|Crime|Drama|Mystery', 'Comedy|Crime|Mystery|Thriller',\n",
       "       'Film-Noir|Sci-Fi|Thriller', 'Adventure|Sci-Fi|Thriller',\n",
       "       'Crime|Drama|Mystery|Thriller', 'Comedy|Documentary',\n",
       "       'Documentary|Musical', 'Action|Drama|Sci-Fi|Thriller',\n",
       "       \"Adventure|Animation|Children's|Fantasy\",\n",
       "       'Adventure|Comedy|Romance', 'Mystery|Sci-Fi|Thriller',\n",
       "       'Action|Comedy|Crime', \"Animation|Children's|Fantasy|War\",\n",
       "       'Action|Crime|Drama|Thriller', 'Comedy|Sci-Fi|Western',\n",
       "       \"Children's|Fantasy|Musical\", 'Fantasy|Sci-Fi',\n",
       "       \"Children's|Comedy|Sci-Fi\", \"Action|Adventure|Children's|Comedy\",\n",
       "       \"Adventure|Children's|Drama|Romance\",\n",
       "       \"Adventure|Children's|Sci-Fi\",\n",
       "       \"Adventure|Children's|Comedy|Fantasy|Sci-Fi\",\n",
       "       \"Animation|Children's|Comedy|Musical|Romance\",\n",
       "       \"Children's|Musical\", 'Drama|Fantasy',\n",
       "       \"Animation|Children's|Fantasy|Musical\", 'Adventure|Comedy|Musical',\n",
       "       \"Children's|Sci-Fi\", \"Children's|Horror\", 'Comedy|Fantasy|Romance',\n",
       "       'Comedy|Crime|Thriller', \"Adventure|Animation|Children's|Sci-Fi\",\n",
       "       'Action|Crime|Mystery|Thriller', 'Adventure|Musical',\n",
       "       \"Animation|Children's|Drama|Fantasy\", \"Children's|Fantasy|Sci-Fi\",\n",
       "       'Adventure|Fantasy|Romance', 'Crime|Horror',\n",
       "       'Action|Adventure|Horror', 'Adventure|Fantasy|Sci-Fi',\n",
       "       'Drama|Film-Noir|Thriller', 'Action|Comedy|Fantasy',\n",
       "       'Sci-Fi|Thriller|War', 'Action|Adventure|Sci-Fi|Thriller|War',\n",
       "       'Action|Adventure|Drama|Thriller', 'Crime|Horror|Thriller',\n",
       "       'Animation|Musical', 'Action|War',\n",
       "       'Action|Comedy|Romance|Thriller', 'Comedy|Horror|Thriller',\n",
       "       'Drama|Horror|Thriller', 'Action|Sci-Fi|Thriller|Western',\n",
       "       'Drama|Romance|Sci-Fi', 'Action|Adventure|Horror|Thriller',\n",
       "       'Comedy|Film-Noir|Thriller', 'Comedy|Horror|Musical|Sci-Fi',\n",
       "       'Comedy|Romance|Sci-Fi', 'Action|Comedy|Sci-Fi|Thriller',\n",
       "       'Action|Sci-Fi|Western', 'Comedy|Horror|Musical', 'Crime|Mystery',\n",
       "       'Animation|Mystery', 'Action|Horror|Thriller',\n",
       "       'Action|Drama|Fantasy|Romance', 'Horror|Mystery',\n",
       "       \"Adventure|Animation|Children's\", 'Musical|Romance|War',\n",
       "       'Adventure|Drama|Romance', 'Adventure|Animation|Film-Noir',\n",
       "       'Action|Adventure|Animation', 'Comedy|Drama|Western',\n",
       "       'Adventure|Comedy|Sci-Fi', 'Drama|Romance|Western',\n",
       "       'Comedy|Drama|Sci-Fi', 'Action|Drama|Romance|Thriller',\n",
       "       'Adventure|Romance|Sci-Fi', 'Film-Noir|Horror',\n",
       "       'Crime|Drama|Film-Noir|Thriller', 'Action|Adventure|War',\n",
       "       'Romance|Western', \"Action|Children's|Fantasy\",\n",
       "       'Adventure|Drama|Thriller', 'Adventure|Fantasy', 'Musical|War',\n",
       "       'Adventure|Musical|Romance', 'Action|Romance|Sci-Fi',\n",
       "       'Drama|Film-Noir', 'Comedy|Horror|Sci-Fi',\n",
       "       'Adventure|Drama|Romance|Sci-Fi', 'Adventure|Animation|Sci-Fi',\n",
       "       'Adventure|Crime|Sci-Fi|Thriller'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.genres.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_second(genre):\n",
    "    try:\n",
    "        return genre.split(\"|\")[1]\n",
    "    except IndexError:\n",
    "        return \"missing\"\n",
    "    \n",
    "def split_third(genre):\n",
    "    try:\n",
    "        return genre.split(\"|\")[2]\n",
    "    except IndexError:\n",
    "        return \"missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['first_genre'] = movies.genres.apply(lambda x: x.split(\"|\")[0])\n",
    "movies['second_genre'] = movies.genres.apply(split_second)\n",
    "movies['third_genre'] = movies.genres.apply(split_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies.drop(\"genres\", axis=1, inplace=True)\n",
    "ratings.drop(\"timestamp\", axis=1, inplace=True)\n",
    "users.drop(\"zipcode\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(ratings, users, how=\"left\", on=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data, movies, how=\"left\", on=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "data['title'] = oe.fit_transform(data.title.values.reshape(-1,1)).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>title</th>\n",
       "      <th>first_genre</th>\n",
       "      <th>second_genre</th>\n",
       "      <th>third_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2452</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1739</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2289</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1054</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2654</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>346</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>671</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3055</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3656</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating gender  age  occupation title first_genre second_genre  \\\n",
       "0     1  1193       5      F    1          10  2452       Drama      missing   \n",
       "1     1   661       3      F    1          10  1739   Animation   Children's   \n",
       "2     1   914       3      F    1          10  2289     Musical      Romance   \n",
       "3     1  3408       4      F    1          10  1054       Drama      missing   \n",
       "4     1  2355       5      F    1          10   557   Animation   Children's   \n",
       "5     1  1197       3      F    1          10  2654      Action    Adventure   \n",
       "6     1  1287       5      F    1          10   346      Action    Adventure   \n",
       "7     1  2804       5      F    1          10   671      Comedy        Drama   \n",
       "8     1   594       4      F    1          10  3055   Animation   Children's   \n",
       "9     1   919       4      F    1          10  3656   Adventure   Children's   \n",
       "\n",
       "  third_genre  \n",
       "0     missing  \n",
       "1     Musical  \n",
       "2     missing  \n",
       "3     missing  \n",
       "4      Comedy  \n",
       "5      Comedy  \n",
       "6       Drama  \n",
       "7     missing  \n",
       "8     Musical  \n",
       "9       Drama  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>title</th>\n",
       "      <th>first_genre</th>\n",
       "      <th>second_genre</th>\n",
       "      <th>third_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Ben-Hur (1959)</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Christmas Story, A (1983)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Wizard of Oz, The (1939)</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating gender  age  occupation  \\\n",
       "0     1  1193       5      F    1          10   \n",
       "1     1   661       3      F    1          10   \n",
       "2     1   914       3      F    1          10   \n",
       "3     1  3408       4      F    1          10   \n",
       "4     1  2355       5      F    1          10   \n",
       "5     1  1197       3      F    1          10   \n",
       "6     1  1287       5      F    1          10   \n",
       "7     1  2804       5      F    1          10   \n",
       "8     1   594       4      F    1          10   \n",
       "9     1   919       4      F    1          10   \n",
       "\n",
       "                                    title first_genre second_genre third_genre  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)       Drama      missing     missing  \n",
       "1        James and the Giant Peach (1996)   Animation   Children's     Musical  \n",
       "2                     My Fair Lady (1964)     Musical      Romance     missing  \n",
       "3                  Erin Brockovich (2000)       Drama      missing     missing  \n",
       "4                    Bug's Life, A (1998)   Animation   Children's      Comedy  \n",
       "5              Princess Bride, The (1987)      Action    Adventure      Comedy  \n",
       "6                          Ben-Hur (1959)      Action    Adventure       Drama  \n",
       "7               Christmas Story, A (1983)      Comedy        Drama     missing  \n",
       "8  Snow White and the Seven Dwarfs (1937)   Animation   Children's     Musical  \n",
       "9                Wizard of Oz, The (1939)   Adventure   Children's       Drama  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"ml-1m/merged_data.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(include_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset size before:  200005\n",
      "testset size after:  200005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7fcb813d61d0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.build_dataset(\"ml-1m/merged_data.csv\", length=\"all\", user_col=0, item_col=1, label_col=2, \n",
    "                     numerical_col=[4], categorical_col=[3,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     2,     7, ...,  3750,  3751,  9791],\n",
       "       [    0,     1,    15, ...,  3750,  3752,  9792],\n",
       "       [    0,     2,     3, ...,  3750,  3753,  9793],\n",
       "       ...,\n",
       "       [    0,     1,    18, ...,  3750,  5061, 12315],\n",
       "       [    0,     2,     4, ...,  3750,  9690, 10318],\n",
       "       [    0,     2,     3, ...,  3750,  6439,  9793]], dtype=int32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_feat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     2,    19, ...,  3750,  5764, 11115],\n",
       "       [    0,     1,     8, ...,  3750,  7849, 10401],\n",
       "       [    0,     2,    21, ...,  3750,  6642, 10998],\n",
       "       ...,\n",
       "       [    0,     1,    11, ...,  3750,  3904, 10950],\n",
       "       [    0,     2,    20, ...,  3745,  4186, 10515],\n",
       "       [    0,     2,     3, ...,  3746,  7888, 10965]], dtype=int32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.test_feat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [45.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [25.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [18.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [35.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [18.,  1.,  1., ...,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_feat_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800168, 9), 13465)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_feat_indices.shape, dataset.train_feat_indices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13466"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(data.columns)\n",
    "cols.remove('age')\n",
    "cols.remove('rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user',\n",
       " 'item',\n",
       " 'gender',\n",
       " 'occupation',\n",
       " 'title',\n",
       " 'first_genre',\n",
       " 'second_genre',\n",
       " 'third_genre']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n",
      "3706\n",
      "2\n",
      "21\n",
      "3706\n",
      "18\n",
      "18\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "total_cols = 0\n",
    "for col in cols:\n",
    "    print(data[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3675"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(dataset.train_feat_indices[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user             int64\n",
       "item             int64\n",
       "rating           int64\n",
       "gender          object\n",
       "age              int64\n",
       "occupation       int64\n",
       "title           object\n",
       "first_genre     object\n",
       "second_genre    object\n",
       "third_genre     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>title</th>\n",
       "      <th>first_genre</th>\n",
       "      <th>second_genre</th>\n",
       "      <th>third_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2452</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1739</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2289</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1054</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2654</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>346</td>\n",
       "      <td>Action</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>671</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3055</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3656</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating gender  age  occupation title first_genre second_genre  \\\n",
       "0     1  1193       5      F    1          10  2452       Drama      missing   \n",
       "1     1   661       3      F    1          10  1739   Animation   Children's   \n",
       "2     1   914       3      F    1          10  2289     Musical      Romance   \n",
       "3     1  3408       4      F    1          10  1054       Drama      missing   \n",
       "4     1  2355       5      F    1          10   557   Animation   Children's   \n",
       "5     1  1197       3      F    1          10  2654      Action    Adventure   \n",
       "6     1  1287       5      F    1          10   346      Action    Adventure   \n",
       "7     1  2804       5      F    1          10   671      Comedy        Drama   \n",
       "8     1   594       4      F    1          10  3055   Animation   Children's   \n",
       "9     1   919       4      F    1          10  3656   Adventure   Children's   \n",
       "\n",
       "  third_genre  \n",
       "0     missing  \n",
       "1     Musical  \n",
       "2     missing  \n",
       "3     missing  \n",
       "4      Comedy  \n",
       "5      Comedy  \n",
       "6       Drama  \n",
       "7     missing  \n",
       "8     Musical  \n",
       "9       Drama  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
